{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b332514-9116-4b4d-9844-567c3388e798",
   "metadata": {},
   "source": [
    "# Interactive Cellpose 3D training workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f470c-3542-42ad-9175-f47066319268",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Upsampling Z dimension\n",
    "Check how the image would look when Z sampling is rescaled to be isotropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779b9e0-fdbd-40ca-974e-34ac9b98638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from skimage.transform import rescale\n",
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e9353-33ff-43ab-97ab-a3e26a04771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a 3D image\n",
    "img_path = '/Users/joel/Desktop/object_8/220508_215839_B03_T0001F001L01A04Z01C01O00008_TIF-OVR.tif'\n",
    "img = imageio.volread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1af37-3ad5-4259-9c4b-e819ea690daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upscale the Z dimension to be isotropic\n",
    "anisotropy = 2.7\n",
    "img_rescaled = rescale(img, scale=(anisotropy, 1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72284438-98b3-4867-ae6e-78eaa783a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the image in the viewer\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img)\n",
    "viewer.add_image(img_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41815e-1e1a-4140-a670-baf87f46b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save rescaled image\n",
    "output_path = '/Users/joel/Desktop/object_8/220508_215839_C01_Rescaled.tif'\n",
    "imageio.volwrite(output_path, img_rescaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb3470f-94d6-4b9e-aaf9-a8d1100be9c3",
   "metadata": {},
   "source": [
    "# Annotation & training workflow\n",
    "\n",
    "Cellpose is trained on 2D slices. Thus, we generate an isotropic 3D image by upsampling the same way that cellpose uses internally. Then, we run cellpose on this 3D image and pick some planes. We correct these planes and feed them into model training.\n",
    "Iteratively run this workflow until the model is good enough.\n",
    "\n",
    "1. Run Cellpose with a given parameters  \n",
    "    a) With a default model or a custom one\n",
    "2. Browse the result in napari, check performance\n",
    "    a) optionally check the flows to see why the performance suffered\n",
    "3. Get a few planes you want to retrain the model on (choose e.g. 3 xy, 3 xz or yz planes)  \n",
    "    a) Correct the labels for these planes. You can check the other planes to ensure you feed in correct training data\n",
    "    b) Save those planes to the train_dir / test_dir folder. Add some to the test set to evaluate whether the training has a generalizable effect\n",
    "4. Run a retraining on those images\n",
    "5. Then apply the network to a new 3D organoid => start again at 1)\n",
    "    a) Alternatively, apply it back to the same 3D data and correct different planes\n",
    "    \n",
    "Training workflow is based on https://colab.research.google.com/github/MouseLand/cellpose/blob/main/notebooks/run_cellpose_2.ipynb#scrollTo=gCcbs722BYd0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af60fe-4b2d-4796-862f-636533c9101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import models, io\n",
    "import imageio\n",
    "from skimage.transform import rescale\n",
    "import napari\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d20d31c-b7c9-4aaf-8b66-224bd61c3f8d",
   "metadata": {},
   "source": [
    "### 1. Run a cellpose model on some 3D images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727399a-2014-4c5d-8cce-4f673c8504e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img_path = '/Users/joel/Desktop/object_8/220508_215839_B03_T0001F001L01A04Z01C01O00008_TIF-OVR.tif'\n",
    "img = imageio.volread(img_path)\n",
    "# Important: Set anisotropy correctly based on the Z spacing!\n",
    "anisotropy = 2.7\n",
    "\n",
    "# Should you correct anisotropy in the image itself, before passing it to cellpose?\n",
    "# Useful to generate isotropic data, the same as the cellpose model does internally. \n",
    "# Thus, useful when we want to generate new training cases. \n",
    "# But not what we want to look at eventaully (when predicting on the real data)\n",
    "correct_anisotropy = True\n",
    "if correct_anisotropy:\n",
    "    img = rescale(img, scale=(anisotropy, 1.0, 1.0))\n",
    "    anisotropy = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad4d96-2192-4104-8320-c25318fc2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run the cellpose model\n",
    "def run_cellpose_model(\n",
    "                       img,\n",
    "                       do_3D = True,\n",
    "                       anisotropy = 2.7,\n",
    "                       model = 'cyto2',\n",
    "                       pretrained_model = None,\n",
    "                       cellprob_th = 0.0,\n",
    "                       diameter = 35,\n",
    "                       channels=[0,0],\n",
    "                       use_GPU = True\n",
    "                      ):\n",
    "    logger = io.logger_setup()\n",
    "    # Run cellpose model inference\n",
    "    if pretrained_model:\n",
    "        model = models.CellposeModel(gpu=use_GPU, pretrained_model=pretrained_model)\n",
    "    else:\n",
    "        model = models.CellposeModel(gpu=use_GPU, model_type=model)\n",
    "    mask, flows, styles = model.eval(img, \n",
    "                                            channels=channels, \n",
    "                                            diameter=diameter, \n",
    "                                            anisotropy=anisotropy, \n",
    "                                            do_3D=do_3D, \n",
    "                                            #net_avg=False, \n",
    "                                            #augment=False, \n",
    "                                            cellprob_threshold=cellprob_th)\n",
    "        \n",
    "    return mask, flows, styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a0bce-6c3c-4f88-921d-fca8790d69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter = 35\n",
    "model_type = \"cyto2\"\n",
    "mask, flows, _ = run_cellpose_model(img, anisotropy=anisotropy, diameter=diameter, model=model_type)\n",
    "\n",
    "# Use this approach to run a pretrained model later\n",
    "#pretrained_model = '/Users/joel/Dropbox/Joel/FMI/Code/cellpose/models/retrained_cyto2'\n",
    "#mask, flows, _ = run_cellpose_model(img, anisotropy=anisotropy, diameter=diameter, pretrained_model=pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad8a37-4cfb-4824-bf04-9d85094865d4",
   "metadata": {},
   "source": [
    "### 2. Browse the result in napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7645696-b8f6-4294-923f-967b7cdd5bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "image_layer = viewer.add_image(img, scale = (anisotropy, 1, 1))\n",
    "label_layer = viewer.add_labels(mask, scale = (anisotropy, 1, 1))\n",
    "viewer.add_image(flows[0], scale = (anisotropy, 1, 1), name = 'Flows', visible=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ba23e5-6d15-43ba-94bc-dfc4ccae4f12",
   "metadata": {},
   "source": [
    "### 3. Export corrected annotation planes\n",
    "Make sure the labels are good for the planes you want to export as new training data\n",
    "\n",
    "Then, enter the index of the plane in the training or test list to export it into that directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f2401-d146-43e0-8942-8ab5a6c3599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def save_img(img, base_name, plane, dir_path):\n",
    "    imageio.imwrite(Path(dir_path) / f'{base_name}_{plane}.tif', img)\n",
    "    \n",
    "def save_label(label_img, base_name, plane, dir_path):\n",
    "    # TODO: Do those need to be .npy pickle files or does it accept tifs?\n",
    "    imageio.imwrite(Path(dir_path) / f'{base_name}_{plane}_seg.tif', label_img)\n",
    "\n",
    "def save_new_annotations(plane_list, dimension, save_dir, base_name):\n",
    "    for plane in plane_list:\n",
    "        if dimension == 0:\n",
    "            img_plane = image_layer.data[plane, :, :]\n",
    "            label_plane = label_layer.data[plane, :, :]\n",
    "        elif dimension == 1:\n",
    "            img_plane = image_layer.data[:, plane, :]\n",
    "            label_plane = label_layer.data[:, plane, :]\n",
    "        elif dimension == 2:\n",
    "            img_plane = image_layer.data[:, :, plane]\n",
    "            label_plane = label_layer.data[:, :, plane]\n",
    "        else:\n",
    "            print('Not a valid dimension chosen')\n",
    "            return\n",
    "        plane_names = {0: 'xy', 1: 'xz', 2: 'yz'}\n",
    "        new_base_name = base_name + '_' + plane_names[dimension]\n",
    "        save_img(img_plane, base_name = new_base_name, plane = plane, dir_path = save_dir)\n",
    "        save_label(label_plane, base_name = new_base_name, plane = plane, dir_path = save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d10ca-a0f3-4c44-b2c0-9d2426d8a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export individual planes (both image data and labels)\n",
    "base_name = '220508_215839_B03_T0001F001L01A04Z01C01O00008'\n",
    "train_dir = 'train_dir'\n",
    "test_dir = 'test_dir'\n",
    "\n",
    "# The xy plane\n",
    "xy_planes_train = []\n",
    "xy_panes_test = []\n",
    "# The yz plane, the one you see by pressing the flip dimension button once in napari\n",
    "yz_planes_train = []\n",
    "yz_planes_test = []\n",
    "# The xz plane, the one you see by pressing the flip dimension button twice in napari\n",
    "xz_planes_train = []\n",
    "xz_planes_test = []\n",
    "\n",
    "training_lists = [xy_planes_train, xz_planes_train, yz_planes_train]\n",
    "test_lists = [xy_panes_test, xz_planes_test, yz_planes_test]\n",
    "\n",
    "for dimension, curr_list in enumerate(training_lists):\n",
    "    save_new_annotations(\n",
    "        plane_list = curr_list, \n",
    "        dimension = dimension,\n",
    "        save_dir = train_dir,\n",
    "        base_name = base_name,\n",
    "    )\n",
    "\n",
    "for dimension, curr_list in enumerate(test_lists):\n",
    "    save_new_annotations(\n",
    "        plane_list = curr_list, \n",
    "        dimension = dimension,\n",
    "        save_dir = test_dir,\n",
    "        base_name = base_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dec1aa-2224-4c71-96b5-b7bcb1e6b3f4",
   "metadata": {},
   "source": [
    "### 4. Retrain the cellpose model\n",
    "Currently always retraining from the base model. One could also iteratively retrain by having different training directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8591b6-a6be-455b-b83d-35b5b021b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to change\n",
    "# Make this unique for every new network you train. Otherwise, it overwrites the existing network\n",
    "model_name = \"retrained_cyto2\"\n",
    "\n",
    "initial_model = 'cyto2'\n",
    "model_dir = '/Users/joel/Dropbox/Joel/FMI/Code/cellpose/models'\n",
    "# On Macs, using the GPU for training leads to \n",
    "# `RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn`\n",
    "# If it works on your machine, set the use_GPU=True\n",
    "use_GPU = False\n",
    "# Works when a single input channel is used\n",
    "channels = [0, 0]\n",
    "n_epochs = 100\n",
    "\n",
    "# Don't change these 2 parameters\n",
    "weight_decay = 0.0001\n",
    "learning_rate = 0.1\n",
    "\n",
    "model = models.CellposeModel(gpu=use_GPU, model_type=initial_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6540f-49e3-4268-966f-ca1b3645f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data & labels from disk\n",
    "# FIXME: Hacky way, make this more robust\n",
    "def load_train_data(train_dir, mask_filter = '_seg.tif'):\n",
    "    files = glob.glob(str(Path(train_dir) / '*.tif'))\n",
    "    train_paths = [f for f in files if not f.endswith(mask_filter)]\n",
    "    label_paths = [f[:-4] + mask_filter for f in train_paths]\n",
    "    train_imgs = []\n",
    "    for train_p in train_paths:\n",
    "        train_imgs.append(imageio.v2.imread(train_p))\n",
    "    label_imgs = []\n",
    "    for label_p in label_paths:\n",
    "        label_imgs.append(imageio.v2.imread(label_p))\n",
    "    return train_imgs, label_imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e9732-7de6-4330-a8a6-c6694fa12b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train_dir'\n",
    "train_data, train_labels = load_train_data(train_dir)\n",
    "\n",
    "test_dir = 'test_dir'\n",
    "test_data, test_labels = load_train_data(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7fe969-4951-4b85-944e-e659ffad01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have no test data, comment out the two lines with test_data & test_labels\n",
    "logger = io.logger_setup()\n",
    "new_model_path = model.train(train_data, train_labels, \n",
    "                              test_data=test_data,\n",
    "                              test_labels=test_labels,\n",
    "                              channels=channels, \n",
    "                              save_path=model_dir, \n",
    "                              n_epochs=n_epochs,\n",
    "                              learning_rate=learning_rate, \n",
    "                              weight_decay=weight_decay, \n",
    "                              nimg_per_epoch=8,\n",
    "                              model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69268f70-5f05-4a7c-b93e-afe45aacbb01",
   "metadata": {},
   "source": [
    "# Run 2 channell setup\n",
    "Alternative mode that can handle a 2 channel setup for cell segmentation, using both a nuclear channel and a cell channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e697a-a712-4cfb-95a3-c54ebfaee87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import models, io\n",
    "import imageio\n",
    "from skimage.transform import rescale\n",
    "import napari\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154065ac-cd19-4290-9ae3-3e7f7bbd93e3",
   "metadata": {},
   "source": [
    "### 1. Run a cellpose model on some 3D images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c46be9b-bcd4-41b0-8fa8-5dd742880923",
   "metadata": {},
   "outputs": [],
   "source": [
    "memb_path = \"/Users/joel/Desktop/object_4/230902NARibidi04a_021223_215326_A04_T0001F001L01A01Z01C04O00004_TIF-OVR.tif\"\n",
    "nuc_path = \"/Users/joel/Desktop/object_4/230902NARibidi04a_021223_215326_A04_T0001F001L01A01Z01C01O00004_TIF-OVR.tif\"\n",
    "\n",
    "# Load the image\n",
    "nuc_img = imageio.volread(nuc_path)\n",
    "memb_img = imageio.volread(memb_path)\n",
    "# Important: Set anisotropy correctly based on the Z spacing!\n",
    "anisotropy = 2.8\n",
    "\n",
    "# Should you correct anisotropy in the image itself, before passing it to cellpose?\n",
    "# Useful to generate isotropic data, the same as the cellpose model does internally. \n",
    "# Thus, useful when we want to generate new training cases. \n",
    "# But not what we want to look at eventaully (when predicting on the real data)\n",
    "correct_anisotropy = True\n",
    "if correct_anisotropy:\n",
    "    nuc_img = rescale(nuc_img, scale=(anisotropy, 1.0, 1.0))\n",
    "    memb_img = rescale(memb_img, scale=(anisotropy, 1.0, 1.0))\n",
    "    anisotropy = 1.0\n",
    "\n",
    "comb_channel = np.zeros((tuple([2] + list(nuc_img.shape))))\n",
    "comb_channel[0, :, :, :] = memb_img\n",
    "comb_channel[1, :, :, :] = nuc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2490f15b-fa14-4aeb-be2e-ba48eccdbdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To crop out part of an image, \n",
    "# e.g. cut out the lowest Z planes and only go until z plane 400\n",
    "# use an approach like this:\n",
    "#comb_channel = comb_channel[:, 20:400, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63969100-2f6b-4d9f-80bb-a2159a1ae06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run the cellpose model\n",
    "def run_cellpose_model(\n",
    "                       img,\n",
    "                       do_3D = True,\n",
    "                       anisotropy = 2.7,\n",
    "                       model = 'cyto2',\n",
    "                       pretrained_model = None,\n",
    "                       cellprob_th = 0.0,\n",
    "                       diameter = 35,\n",
    "                       channels=[1,2],\n",
    "                       use_GPU = True\n",
    "                      ):\n",
    "    logger = io.logger_setup()\n",
    "    # Run cellpose model inference\n",
    "    if pretrained_model:\n",
    "        model = models.CellposeModel(gpu=use_GPU, pretrained_model=pretrained_model)\n",
    "    else:\n",
    "        model = models.CellposeModel(gpu=use_GPU, model_type=model)\n",
    "    mask, flows, styles = model.eval(img, \n",
    "                                            channels=channels, \n",
    "                                            diameter=diameter, \n",
    "                                            anisotropy=anisotropy, \n",
    "                                            do_3D=do_3D, \n",
    "                                            #net_avg=False, \n",
    "                                            #augment=False, \n",
    "                                            cellprob_threshold=cellprob_th)\n",
    "        \n",
    "    return mask, flows, styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdcf010-dd24-4956-b55d-3f4157aee308",
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter = 70\n",
    "model_type = \"cyto2\"\n",
    "mask, flows, _ = run_cellpose_model(comb_channel, anisotropy=anisotropy, diameter=diameter, model=model_type)\n",
    "\n",
    "# Use this approach to run a pretrained model later\n",
    "#pretrained_model = '/Users/joel/Dropbox/Joel/FMI/Code/cellpose/models/models/retrained_cyto2_dualChannel'\n",
    "#mask, flows, _ = run_cellpose_model(comb_channel, anisotropy=anisotropy, diameter=diameter, pretrained_model=pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad71a64-0938-4432-bc0c-c14fa8383a3b",
   "metadata": {},
   "source": [
    "### 2. Browse the result in napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f32f7b1-b9b7-4557-b8ee-a8f4edc06da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "image_layer_nuc = viewer.add_image(comb_channel[1], scale = (anisotropy, 1, 1), colormap='cyan')\n",
    "image_layer_memb = viewer.add_image(comb_channel[0], scale = (anisotropy, 1, 1), colormap='green', blending = 'additive')\n",
    "label_layer = viewer.add_labels(mask, scale = (anisotropy, 1, 1))\n",
    "viewer.add_image(flows[0], scale = (anisotropy, 1, 1), name = 'Flows', visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c2c1e-7efe-457a-a7b7-5275e159275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just add the channels to an existing viewer\n",
    "#image_layer_nuc = viewer.add_image(comb_channel[1], scale = (anisotropy, 1, 1), colormap='cyan')\n",
    "#image_layer_memb = viewer.add_image(comb_channel[0], scale = (anisotropy, 1, 1), colormap='green', blending = 'additive')\n",
    "#label_layer = viewer.add_labels(mask, scale = (anisotropy, 1, 1))\n",
    "#viewer.add_image(flows[0], scale = (anisotropy, 1, 1), name = 'Flows', visible=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3619b48a-946a-4e1b-91d6-2891db4fe807",
   "metadata": {},
   "source": [
    "### 3. Export corrected annotation planes\n",
    "Make sure the labels are good for the planes you want to export as new training data\n",
    "\n",
    "Then, enter the index of the plane in the training or test list to export it into that directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb887c0-1c7a-4ac0-9686-1ab7cf0bad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def save_img(img, base_name, plane, dir_path):\n",
    "    imageio.imwrite(Path(dir_path) / f'{base_name}_{plane}.tif', img)\n",
    "    \n",
    "def save_label(label_img, base_name, plane, dir_path):\n",
    "    # TODO: Do those need to be .npy pickle files or does it accept tifs?\n",
    "    imageio.imwrite(Path(dir_path) / f'{base_name}_{plane}_seg.tif', label_img)\n",
    "\n",
    "def save_new_annotations_dual_channel(plane_list, dimension, save_dir, base_name, image_layer_1, image_layer_2, label_plane):\n",
    "    for plane in plane_list:\n",
    "        if dimension == 0:\n",
    "            img_plane_1 = image_layer_1.data[plane, :, :]\n",
    "            img_plane_2 = image_layer_2.data[plane, :, :]\n",
    "            label_plane = label_layer.data[plane, :, :]\n",
    "        elif dimension == 1:\n",
    "            img_plane_1 = image_layer_1.data[:, plane, :]\n",
    "            img_plane_2 = image_layer_2.data[:, plane, :]\n",
    "            label_plane = label_layer.data[:, plane, :]\n",
    "        elif dimension == 2:\n",
    "            img_plane_1 = image_layer_1.data[:, :, plane]\n",
    "            img_plane_2 = image_layer_2.data[:, :, plane]\n",
    "            label_plane = label_layer.data[:, :, plane]\n",
    "        else:\n",
    "            print('Not a valid dimension chosen')\n",
    "            return\n",
    "        plane_names = {0: 'xy', 1: 'xz', 2: 'yz'}\n",
    "        new_base_name = base_name + '_' + plane_names[dimension]\n",
    "        save_img(img_plane_1, base_name = new_base_name + '_c1', plane = plane, dir_path = save_dir)\n",
    "        save_img(img_plane_2, base_name = new_base_name + '_c2', plane = plane, dir_path = save_dir)\n",
    "        save_label(label_plane, base_name = new_base_name, plane = plane, dir_path = save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246af308-f1f7-416c-afe2-a2251b5e3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export individual planes (both image data and labels)\n",
    "base_name = '230902NARibidi04a_021223_215326'\n",
    "train_dir = 'train_dir'\n",
    "test_dir = 'test_dir'\n",
    "\n",
    "# The xy plane\n",
    "xy_planes_train = []\n",
    "xy_panes_test = []\n",
    "# The yz plane, the one you see by pressing the flip dimension button once in napari\n",
    "yz_planes_train = []\n",
    "yz_planes_test = []\n",
    "# The xz plane, the one you see by pressing the flip dimension button twice in napari\n",
    "xz_planes_train = []\n",
    "xz_planes_test = []\n",
    "\n",
    "training_lists = [xy_planes_train, xz_planes_train, yz_planes_train]\n",
    "test_lists = [xy_panes_test, xz_planes_test, yz_planes_test]\n",
    "\n",
    "for dimension, curr_list in enumerate(training_lists):\n",
    "    save_new_annotations_dual_channel(\n",
    "        plane_list = curr_list, \n",
    "        dimension = dimension,\n",
    "        save_dir = train_dir,\n",
    "        base_name = base_name,\n",
    "        image_layer_1=image_layer_memb, \n",
    "        image_layer_2=image_layer_nuc, \n",
    "        label_plane=label_layer\n",
    "    )\n",
    "\n",
    "for dimension, curr_list in enumerate(test_lists):\n",
    "    save_new_annotations_dual_channel(\n",
    "        plane_list = curr_list, \n",
    "        dimension = dimension,\n",
    "        save_dir = test_dir,\n",
    "        base_name = base_name,\n",
    "        image_layer_1=image_layer_memb, \n",
    "        image_layer_2=image_layer_nuc, \n",
    "        label_plane=label_layer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86747a4c-b500-4895-a6a5-93df0d703967",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.volwrite('channel1.tif', comb_channel[0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a24e79-f83c-4647-acea-e0c823526ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.volwrite('channel2.tif', comb_channel[1, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f39d5-c044-44eb-a2b7-94d7eb4c6076",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.volwrite('mask.tif', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf9c96e-5bfe-4f44-914e-061b47d60c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "image_layer_nuc = viewer.add_image(comb_channel[1], scale = (anisotropy, 1, 1), colormap='cyan')\n",
    "image_layer_memb = viewer.add_image(comb_channel[0], scale = (anisotropy, 1, 1), colormap='green')\n",
    "#label_layer = viewer.add_labels(mask, scale = (anisotropy, 1, 1))\n",
    "#viewer.add_image(flows[0], scale = (anisotropy, 1, 1), name = 'Flows', visible=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157346cc-1ece-4d74-946a-f31c725888c1",
   "metadata": {},
   "source": [
    "### 4. Retrain the cellpose model\n",
    "Currently always retraining from the base model. One could also iteratively retrain by having different training directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6af5e4-7c2a-4ae2-9313-c5591696facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Adapt to to channels\n",
    "# Load train data for 2 channel setup & labels from disk\n",
    "# FIXME: Hacky way, make this more robust\n",
    "def load_train_data_2channel(train_dir, mask_filter = '_seg.tif', channels = ['_c1_', '_c2_']):\n",
    "    files = glob.glob(str(Path(train_dir) / '*.tif'))\n",
    "    train_paths = [f for f in files if not f.endswith(mask_filter)]\n",
    "    train_img1_paths = [f for f in train_paths if channels[0] in f]\n",
    "    #train_img2_paths = [f for f in train_paths if channels[1] in f]\n",
    "    label_paths = [f for f in files if f.endswith(mask_filter)]\n",
    "    train_imgs = []\n",
    "    for train_p in train_img1_paths:\n",
    "        img1 = imageio.v2.imread(train_p)\n",
    "        comb_img = np.zeros((tuple([2] + list(img1.shape))))\n",
    "        train_p2 = train_p.replace(channels[0], channels[1])\n",
    "        assert train_p2 in train_paths, f'Could not find channel 2: {train_p2}'\n",
    "        comb_img[0, :, :] = img1\n",
    "        comb_img[1, :, :] = imageio.v2.imread(train_p2)\n",
    "        train_imgs.append(comb_img)\n",
    "    label_imgs = []\n",
    "    for label_p in label_paths:\n",
    "        label_imgs.append(imageio.v2.imread(label_p))\n",
    "    # Checks for consistency between \n",
    "    assert len(train_imgs) == len(label_imgs)\n",
    "    \n",
    "    return train_imgs, label_imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cfbfe5-a310-4d84-89c7-44867b72a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = load_train_data_2channel(train_dir = 'train_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc01096-a52c-4e96-b853-ddde36d67411",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_labels(train_labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2237ecf-ead5-4a9d-9b01-38870ace103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to change\n",
    "# Make this unique for every new network you train. Otherwise, it overwrites the existing network\n",
    "model_name = \"retrained_cyto2_dualChannel\"\n",
    "\n",
    "initial_model = 'cyto2'\n",
    "model_dir = '/Users/joel/Dropbox/Joel/FMI/Code/cellpose/models'\n",
    "# On Macs, using the GPU for training leads to \n",
    "# `RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn`\n",
    "# If it works on your machine, set the use_GPU=True\n",
    "use_GPU = False\n",
    "# Works when a single input channel is used\n",
    "channels = [1, 2]\n",
    "n_epochs = 100\n",
    "\n",
    "# Don't change these 2 parameters\n",
    "weight_decay = 0.0001\n",
    "learning_rate = 0.1\n",
    "\n",
    "model = models.CellposeModel(gpu=use_GPU, model_type=initial_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351eac54-759d-44d8-87ba-b9d00b309ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have no test data, comment out the two lines with test_data & test_labels\n",
    "logger = io.logger_setup()\n",
    "new_model_path = model.train(train_data, train_labels, \n",
    "                              #test_data=test_data,\n",
    "                              #test_labels=test_labels,\n",
    "                              channels=channels, \n",
    "                              save_path=model_dir, \n",
    "                              n_epochs=n_epochs,\n",
    "                              learning_rate=learning_rate, \n",
    "                              weight_decay=weight_decay, \n",
    "                              nimg_per_epoch=8,\n",
    "                              model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c253b8ad-c5c7-4fca-9e54-3c50f8e0bd15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
