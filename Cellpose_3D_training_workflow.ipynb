{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b332514-9116-4b4d-9844-567c3388e798",
   "metadata": {},
   "source": [
    "# Interactive Cellpose 3D training workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f470c-3542-42ad-9175-f47066319268",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Upsampling Z dimension\n",
    "Check how the image would look when Z sampling is rescaled to be isotropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779b9e0-fdbd-40ca-974e-34ac9b98638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from skimage.transform import rescale\n",
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e9353-33ff-43ab-97ab-a3e26a04771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a 3D image\n",
    "img_path = '/Users/joel/Desktop/object_8/220508_215839_B03_T0001F001L01A04Z01C01O00008_TIF-OVR.tif'\n",
    "img = imageio.volread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1af37-3ad5-4259-9c4b-e819ea690daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upscale the Z dimension to be isotropic\n",
    "anisotropy = 2.7\n",
    "img_rescaled = rescale(img, scale=(anisotropy, 1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72284438-98b3-4867-ae6e-78eaa783a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the image in the viewer\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img)\n",
    "viewer.add_image(img_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c41815e-1e1a-4140-a670-baf87f46b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save rescaled image\n",
    "output_path = '/Users/joel/Desktop/object_8/220508_215839_C01_Rescaled.tif'\n",
    "imageio.volwrite(output_path, img_rescaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb3470f-94d6-4b9e-aaf9-a8d1100be9c3",
   "metadata": {},
   "source": [
    "# Annotation & training workflow\n",
    "\n",
    "Cellpose is trained on 2D slices. Thus, we generate an isotropic 3D image by upsampling the same way that cellpose uses internally. Then, we run cellpose on this 3D image and pick some planes. We correct these planes and feed them into model training.\n",
    "Iteratively run this workflow until the model is good enough.\n",
    "\n",
    "1. Run Cellpose with a given parameters  \n",
    "    a) With a default model or a custom one\n",
    "2. Browse the result in napari, check performance\n",
    "    a) optionally check the flows to see why the performance suffered\n",
    "3. Get a few planes you want to retrain the model on (choose e.g. 3 xy, 3 xz or yz planes)  \n",
    "    a) Correct the labels for these planes. You can check the other planes to ensure you feed in correct training data\n",
    "    b) Save those planes to the train_dir / test_dir folder. Add some to the test set to evaluate whether the training has a generalizable effect\n",
    "4. Run a retraining on those images\n",
    "5. Then apply the network to a new 3D organoid => start again at 1)\n",
    "    a) Alternatively, apply it back to the same 3D data and correct different planes\n",
    "    \n",
    "Training workflow is based on https://colab.research.google.com/github/MouseLand/cellpose/blob/main/notebooks/run_cellpose_2.ipynb#scrollTo=gCcbs722BYd0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af60fe-4b2d-4796-862f-636533c9101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import models, io\n",
    "import imageio\n",
    "from skimage.transform import rescale\n",
    "import napari\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d20d31c-b7c9-4aaf-8b66-224bd61c3f8d",
   "metadata": {},
   "source": [
    "### 1. Run a cellpose model on some 3D images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727399a-2014-4c5d-8cce-4f673c8504e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img_path = '/Users/joel/Desktop/object_8/220508_215839_B03_T0001F001L01A04Z01C01O00008_TIF-OVR.tif'\n",
    "img = imageio.volread(img_path)\n",
    "# Important: Set anisotropy correctly based on the Z spacing!\n",
    "anisotropy = 2.7\n",
    "\n",
    "# Should you correct anisotropy in the image itself, before passing it to cellpose?\n",
    "# Useful to generate isotropic data, the same as the cellpose model does internally. \n",
    "# Thus, useful when we want to generate new training cases. \n",
    "# But not what we want to look at eventaully (when predicting on the real data)\n",
    "correct_anisotropy = True\n",
    "if correct_anisotropy:\n",
    "    img = rescale(img, scale=(anisotropy, 1.0, 1.0))\n",
    "    anisotropy = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad4d96-2192-4104-8320-c25318fc2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run the cellpose model\n",
    "def run_cellpose_model(\n",
    "                       img,\n",
    "                       do_3D = True,\n",
    "                       anisotropy = 2.7,\n",
    "                       model = 'cyto2',\n",
    "                       pretrained_model = None,\n",
    "                       cellprob_th = 0.0,\n",
    "                       diameter = 35,\n",
    "                       channels=[0,0],\n",
    "                       use_GPU = True\n",
    "                      ):\n",
    "    logger = io.logger_setup()\n",
    "    # Run cellpose model inference\n",
    "    if pretrained_model:\n",
    "        model = models.CellposeModel(gpu=use_GPU, pretrained_model=pretrained_model)\n",
    "    else:\n",
    "        model = models.CellposeModel(gpu=use_GPU, model_type=model)\n",
    "    mask, flows, styles = model.eval(img, \n",
    "                                            channels=channels, \n",
    "                                            diameter=diameter, \n",
    "                                            anisotropy=anisotropy, \n",
    "                                            do_3D=do_3D, \n",
    "                                            #net_avg=False, \n",
    "                                            #augment=False, \n",
    "                                            cellprob_threshold=cellprob_th)\n",
    "        \n",
    "    return mask, flows, styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a0bce-6c3c-4f88-921d-fca8790d69e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter = 25\n",
    "model_type = \"cyto2\"\n",
    "mask, flows, _ = run_cellpose_model(img, anisotropy=anisotropy, diameter=diameter, model=model_type)\n",
    "\n",
    "# Use this approach to run a pretrained model later\n",
    "#pretrained_model = '/Users/joel/Dropbox/Joel/FMI/Code/cellpose/models/retrained_cyto2'\n",
    "#mask, flows, _ = run_cellpose_model(img, anisotropy=anisotropy, diameter=diameter, pretrained_model=pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad8a37-4cfb-4824-bf04-9d85094865d4",
   "metadata": {},
   "source": [
    "### 2. Browse the result in napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7645696-b8f6-4294-923f-967b7cdd5bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "image_layer = viewer.add_image(img, scale = (anisotropy, 1, 1))\n",
    "label_layer = viewer.add_labels(mask, scale = (anisotropy, 1, 1))\n",
    "viewer.add_image(flows[0], scale = (anisotropy, 1, 1), name = 'Flows', visible=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ba23e5-6d15-43ba-94bc-dfc4ccae4f12",
   "metadata": {},
   "source": [
    "# 3. Export corrected annotation planes\n",
    "Make sure the labels are good for the planes you want to export as new training data\n",
    "\n",
    "Then, enter the index of the plane in the training or test list to export it into that directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d10ca-a0f3-4c44-b2c0-9d2426d8a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export individual planes (both image data and labels)\n",
    "base_name = '220508_215839_B03_T0001F001L01A04Z01C01O00008'\n",
    "train_dir = 'train_dir'\n",
    "test_dir = 'test_dir'\n",
    "\n",
    "xy_planes_train = [129]\n",
    "xy_panes_test = [130]\n",
    "xz_planes_train = []\n",
    "xz_planes_test = []\n",
    "yz_planes_train = []\n",
    "yz_planes_test = []\n",
    "\n",
    "training_lists = [xy_planes_train, xz_planes_train, yz_planes_train]\n",
    "test_lists = [xy_panes_test, xz_planes_test, yz_planes_test]\n",
    "\n",
    "for dimension, curr_list in enumerate(training_lists):\n",
    "    save_new_annotations(\n",
    "        plane_list = curr_list, \n",
    "        dimension = 0,\n",
    "        save_dir = train_dir,\n",
    "        base_name = base_name,\n",
    "    )\n",
    "\n",
    "for dimension, curr_list in enumerate(test_lists):\n",
    "    save_new_annotations(\n",
    "        plane_list = curr_list, \n",
    "        dimension = 0,\n",
    "        save_dir = test_dir,\n",
    "        base_name = base_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f522bc-56d4-449d-aa87-450d21ff136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(img, base_name, plane, dir_path):\n",
    "    imageio.imwrite(Path(dir_path) / f'{base_name}_{plane}.tif', img)\n",
    "    \n",
    "def save_label(label_img, base_name, plane, dir_path):\n",
    "    # TODO: Do those need to be .npy pickle files or does it accept tifs?\n",
    "    imageio.imwrite(Path(dir_path) / f'{base_name}_{plane}_seg.tif', label_img)\n",
    "\n",
    "def save_new_annotations(plane_list, dimension, save_dir, base_name):\n",
    "    for plane in plane_list:\n",
    "        if dimension == 0:\n",
    "            img_plane = image_layer.data[plane, :, :]\n",
    "            label_plane = label_layer.data[plane, :, :]\n",
    "        elif dimmension == 1:\n",
    "            img_plane = image_layer.data[:, plane, :]\n",
    "            label_plane = label_layer.data[:, plane, :]\n",
    "        elif dimmension == 2:\n",
    "            img_plane = image_layer.data[:, :, plane]\n",
    "            label_plane = label_layer.data[:, :, plane]\n",
    "        else:\n",
    "            print('Not a valid dimension chosen')\n",
    "            return\n",
    "        plane_names = {0: 'xy', 1: 'xz', 2: 'yz'}\n",
    "        new_base_name = base_name + '_' + plane_names[dimension]\n",
    "        save_img(img_plane, base_name = new_base_name, plane = plane, dir_path = save_dir)\n",
    "        save_label(label_plane, base_name = new_base_name, plane = plane, dir_path = save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dec1aa-2224-4c71-96b5-b7bcb1e6b3f4",
   "metadata": {},
   "source": [
    "# 4. Retrain the cellpose model\n",
    "Currently always retraining from the base model. One could also iteratively retrain by having different training directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8591b6-a6be-455b-b83d-35b5b021b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to change\n",
    "# Make this unique for every new network you train. Otherwise, it overwrites the existing network\n",
    "model_name = \"retrained_cyto2\"\n",
    "\n",
    "initial_model = 'cyto2'\n",
    "model_dir = '/Users/joel/Dropbox/Joel/FMI/Code/cellpose/models'\n",
    "# On Macs, using the GPU for training leads to \n",
    "# `RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn`\n",
    "# If it works on your machine, set the use_GPU=True\n",
    "use_GPU = False\n",
    "# Works when a single input channel is used\n",
    "channels = [0, 0]\n",
    "n_epochs = 100\n",
    "\n",
    "# Don't change these 2 parameters\n",
    "weight_decay = 0.0001\n",
    "learning_rate = 0.1\n",
    "\n",
    "model = models.CellposeModel(gpu=use_GPU, model_type=initial_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6540f-49e3-4268-966f-ca1b3645f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data & labels from disk\n",
    "# FIXME: Hacky way, make this more robust\n",
    "def load_train_data(train_dir, mask_filter = '_seg.tif'):\n",
    "    files = glob.glob(str(Path(train_dir) / '*.tif'))\n",
    "    train_paths = [f for f in files if not f.endswith(mask_filter)]\n",
    "    label_paths = [f[:-4] + mask_filter for f in train_paths]\n",
    "    train_imgs = []\n",
    "    for train_p in train_paths:\n",
    "        train_imgs.append(imageio.v2.imread(train_p))\n",
    "    label_imgs = []\n",
    "    for label_p in label_paths:\n",
    "        label_imgs.append(imageio.v2.imread(label_p))\n",
    "    return train_imgs, label_imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386e9732-7de6-4330-a8a6-c6694fa12b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train_dir'\n",
    "train_data, train_labels = load_train_data(train_dir)\n",
    "\n",
    "test_dir = 'test_dir'\n",
    "test_data, test_labels = load_train_data(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7fe969-4951-4b85-944e-e659ffad01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have no test data, comment out the two lines with test_data & test_labels\n",
    "logger = io.logger_setup()\n",
    "new_model_path = model.train(train_data, train_labels, \n",
    "                              test_data=test_data,\n",
    "                              test_labels=test_labels,\n",
    "                              channels=channels, \n",
    "                              save_path=model_dir, \n",
    "                              n_epochs=n_epochs,\n",
    "                              learning_rate=learning_rate, \n",
    "                              weight_decay=weight_decay, \n",
    "                              nimg_per_epoch=8,\n",
    "                              model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d65fdd-ce3a-41f7-a9b9-db1ff47275e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
